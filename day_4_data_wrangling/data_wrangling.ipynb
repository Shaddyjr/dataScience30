{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataScience30\n",
    "## [Day 4: Data Wrangling](https://youtu.be/Xn2pzNoP3i0)\n",
    "#### By [Glitched Failure](https://www.youtube.com/channel/UCErSNiDZV4rJCNB8NrDGREA)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "- [Objectives](#Objectives:)\n",
    "- [Code Along](#Code-Along:)\n",
    "- [Assignments](#Assignments:)\n",
    "- [BONUS](#BONUS:)\n",
    "- [Vocabulary](#Vocabulary:)\n",
    "- [References](#References:)\n",
    "- [Have Feedback?](#Have-Feedback?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "- Participants will gain experience loading data from files, web scraping, and APIs\n",
    "- Participants will gain experience writing data to a file\n",
    "- Participants will gain experience creating a data dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Along:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from files\n",
    "We can load a raw CSV file as a DataFrame using `pd.read_csv(\"FILE_PATH\")`\n",
    "\n",
    "Check out the [Pandas DataFrame Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for more on what you can do with a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the \"ads.csv\" file as the variable ads_data\n",
    "ads_data = pd.read_csv(\"ads.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Aside: Relative file paths\n",
    "The file system for this module will look something like this...\n",
    "<img src=\"assets/pathing.png\" width=\"400px\">\n",
    "_NOTE: folders have rounded edges, and files have sharp edges._\n",
    "\n",
    "Notice this notebook and the \"data\" folder are both within the \"day_4_data_wrangling\" folder. They're both on the same level. In order to properly access the \"ads.csv\" file, we need to go into the \"data folder\". Since __code in this notebook executes relative to this file__, we can look at pathing from this file's perspective - that is to say, if we pretended to walk from this file to the file we wanted, we'd have to go into the \"data\" folder and then declare the file name.\n",
    "\n",
    "__Therefore, our file path is \"data/ads.csv\"__, and not just \"ads.csv\".\n",
    "\n",
    "What might you expect the path to the \"wine.csv\" file to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That first column (\"Unnamed: 0\") is odd...it looks more like an index column.\n",
    "\n",
    "After typing in `pd.read_csv()`, try putting your cursor in between the parentheses and press Shift+Tab. This should pull up the help documentation. If you keep pressing Shift+Tab, the window expands.\n",
    "\n",
    "There are plenty of parameters to specify, but we're interested in `index_col`. Let's set the index_col to the 0th column (in python we start counting from 0!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ads_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some basic Pandas Dataframe methods:\n",
    "- `ads_data.tail()`\n",
    "- `ads_data.describe()`\n",
    "- `ads_data.dtypes`\n",
    "- `ads_data.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the \"superstore.xls\" file using the `pd.read_excel()` method and store the data in the variable `store_data`.\n",
    "\n",
    "_Note: be mindful of the relative path to the file and the index column!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out \"store_data.head()\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using `store_data.describe()`. What do you notice is missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical, or string data (AKA the \"object\" datatype), information is not includeded in `.describe()` by default.\n",
    "Try `store_data.describe(include=\"all\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`store_data.describe(include=\"all\")` included ALL of the columns.  \n",
    "Take a moment to make sense of how numeric columns and categorical columns are treated differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type `pd.read_` and press Tab to see the possibilities via auto-complete.\n",
    "\n",
    "As you can see, there are plenty of ways to read in data using Pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from web scraping\n",
    "Web scraping takes advantage of the consistent structure websites have. When a website displays data, there is typically a table or table-like structure to it that we can take advantage of.\n",
    "\n",
    "Web scraping is essentially going to a website and pulling data from it, and parsing out the parts we want into a form we want to work with. For example, I'm interested in a sports team, but don't want to keep track of every little change to the roster over time - there are plenty of websites that already keep track of that kind of thing! I can just write a script that pulls the data from the website and gives me all of the players, their names, performance data, etc.\n",
    "\n",
    "To accomplish this we can use the Beautiful Soup package (there are plenty of web scraping libraries out there, so don't feel married to this one!). Feel free to check out the [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests # this will handle the raw data, which will then be passed to BeautifulSoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website URL where data is\n",
    "URL = \"https://www.espn.com/mlb/team/roster/_/name/nym\"\n",
    "\n",
    "# \"visit\" the website and capture the response\n",
    "response = requests.get(URL)\n",
    "\n",
    "# pull just the HTML text as a large string - we'll feed this into BeautifulSoup\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a BeautifulSoup object named `soup` with the `html` string variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding HTML goes beyond the scope of this course, however, [here is a simple explaination for how HTML structures information](https://www.youtube.com/watch?v=bWPMSSsVdPk).\n",
    "\n",
    "To put it succinctly, HTML content is placed between tags. Tags can be placed inside other tags, and this feature of nesting information is how data is structured in HTML.\n",
    "\n",
    "For example: if we want to display a table with rows and columns we might contain the entire table in its own tag (`<table>...</table>`). Then we can put the header row (`<header_row>...</header_row>`) inside of it. Other rows (`<row>...</row>`) will come after the header_row. Inside each row will be the associated columns (`<column>...</column>`), which contains the raw text data inside of it.\n",
    "\n",
    "```html\n",
    "<table>\n",
    "    <header_row>\n",
    "        <column>Name</column>\n",
    "        <column>Age</column>\n",
    "        <column>Score</column>\n",
    "    </header_row>\n",
    "    \n",
    "    <row>\n",
    "        <column>Bob</column>\n",
    "        <column>19</column>\n",
    "        <column>B-</column>\n",
    "    </row>\n",
    "    \n",
    "    <row>\n",
    "        <column>Sally</column>\n",
    "        <column>34</column>\n",
    "        <column>A+</column>\n",
    "    </row>\n",
    "</table>\n",
    "```\n",
    "\n",
    "Becomes...\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Name</th>\n",
    "        <th>Age</th>\n",
    "        <th>Score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bob</td>\n",
    "        <td>19</td>\n",
    "        <td>B-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Sally</td>\n",
    "        <td>34</td>\n",
    "        <td>A+</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `soup` object has a bunch of methods for querying the information inside of the HTML, which can actually be chained.  \n",
    "\n",
    "Use the `.find()` method to find the first \"table\", and store it in the variable `table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `table` object is much like the `soup` object, except it ONLY contains the information inside of the table. This tends to be easier to work with than the entire HTML document.\n",
    "\n",
    "_NOTE: In the earlier example, I simplified the tag names to keep things clear. The actual tag names are \"tr\" for `<row>` and \"td\" for `<column>`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .find_all() to get all of the \"tr\" elements within the table object and store the results in the \"rows\" variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variable \"contents\" as an empty list\n",
    "contents = []\n",
    "\n",
    "# Loop through each row in rows and append the result of calling `.get_text(\";\")` on each row\n",
    "for row in rows:\n",
    "    contents.append(row.get_text(\";\")) #gathers text for each row with semi-colon, \";\", as delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the contents list\n",
    "contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: There really is no single correct approach to web scrapping. The steps before and after this point came from much trial and error as well as familiarity with the website. If you plan to scrap data, be prepared to do the same!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The headers were off by 1 column because of how the website puts the name and player number together\n",
    "headers = contents.pop(0).split(\";\")\n",
    "headers.insert(1,\"Num\")\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting everything into a DataFrame\n",
    "data_splits = [s.split(\";\") for s in contents]\n",
    "players_data = pd.DataFrame(data_splits, columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Aside: robots.txt\n",
    "Web scrapping can be easy once you have a script up and running. \n",
    "\n",
    "HOWEVER, automated web queries can cause havoc to even the most robust servers, which is why __most web servers include a \"robots.txt\" file, which details the expected behavior developers should employ when automactically querying their servers.__  \n",
    "\n",
    "It's important to __be respectful__ and not cause an undue burden on someone else. Doing so can __quickly get you banned or blacklisted__. So, exercise discretion when scrapping website by checking the \"robots.txt\" file BEFORE even thinking about scrapping from a site.\n",
    "\n",
    "You can typically go to the main website you WOULD want to scrap from and in the URL add \"/robots.txt\" to see which users agents are allowed to do what. \n",
    "\n",
    "For example: https://twitter.com => https://twitter.com/robots.txt\n",
    "\n",
    "As you can see, Twitter has a LOT of consideration for who is querying their servers. Since you likely won't have a bot or user-agent already defined in this file, you will fall under the blanket user-agent `User-agent: *` (near bottom). Here, you can see which routes are restricted and allowed.\n",
    "\n",
    "For example: https://www.reddit.com => https://www.reddit.com/robots.txt\n",
    "\n",
    "Reddit has a similar set of concerns, but very different permissions for `User-agent: *`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Aside: delaying requests\n",
    "\n",
    "In addition to respecting how server maintainers wish their servers to be treated, you can purposefully delay repeated requests using the `time` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from an API\n",
    "\n",
    "The last major way data is made accessible is through an API interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is an API?\n",
    "\n",
    "API stands for Application Program Interface, which is just a fancy way of saying computers talking to other computers.\n",
    "\n",
    "When we humans access a website, we enjoy a visually appealing website with nice interactions. Computers don't require such nicities - instead, raw data is often transferred in some standard format (usually JSON).\n",
    "\n",
    "JSON stands for JavaScript Object Notation. No, we won't be learning JavaScript! This if JSON as just a basic format for how raw data is transferred between computers and look something like this...\n",
    "\n",
    "```javascript\n",
    "{\n",
    "    \"some_key\" : \"some value\",\n",
    "    \"an_array_or_list\" : [1,2,3],\n",
    "    \"an_object_or_dictionary\" : {\n",
    "        \"another_key\":\"another value\"\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `requests` library again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's request a random user from the [Random User API](https://randomuser.me/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://randomuser.me/api/\"\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this request look like?\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in response between this API URL and the website URL we ran before. This is not HTML, it's JSON!\n",
    "\n",
    "As a convenience, the response object has a `.json()` method, which turns the JSON text into a python dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = response.json()\n",
    "random_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can access the data directly and do whatever we typically would in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gender of the random_user\n",
    "random_user[\"results\"][0][\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the username of the random_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the large picture of the random_user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling URL parameters\n",
    "\n",
    "Typically APIs allow you to query their database through URL parameters. URL parameters are added at the end of a URL and gives more context to the request.\n",
    "\n",
    "For example, the [Random User API](https://randomuser.me/) will allow you to request multiple random users, but you'll have to tell it how many you want within the URL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://randomuser.me/api/\"\n",
    "number_of_users = 10\n",
    "URL = \"{}?results={}\".format(BASE_URL, number_of_users)\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out what the final URL looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the separation of the base url and the parameters is done with a question mark, ?.\n",
    "\n",
    "Also, the parameters come in the form a key:value pairs, which are separated by an equal sign, =."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random users are found in the results?\n",
    "len(response.json()[\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional parameters is a simple as including more key:value pairs, except the pairs themselves are separated by an ampersand, &."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://randomuser.me/api/\"\n",
    "number_of_users = 10\n",
    "gender = \"female\"\n",
    "URL = \"{}?results={}&gender={}\".format(BASE_URL, number_of_users, gender)\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling an API requiring an API Key\n",
    "\n",
    "The above previous APIs are great tools for learning about APIs.  \n",
    "\n",
    "However, more often than not, an API will require you register or have an account with the service. You will be given an API KEY, which is used by the server maintainers to \"keep the peace\" and ensure users are not abusing the service (i.e. \"spamming\" the server causing a \"denial of service\"). \n",
    "\n",
    "Often, an API will include some quota restricting how often you are allowed to ping the API. Again, this is used to ensure the server runs smoothly for all users and you'll need to check the API documentation to learn exactly how you're expected to work with the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Go to http://www.omdbapi.com/ and register for an API Key__ (for \"Account Type\" select \"Free! (1000 daily limit)\"). Your API key will be emailed to you and your account will require activation via that same email. This process is fairly representative of other API services.\n",
    "\n",
    "_NOTE: Your API Key is akin to your username and password. NEVER disclose your API Key!_\n",
    "\n",
    "_NOTE: This course is not endorsed by or affiliated with OMDb. As of this writing, the OMDb API is simply easy to use as an example API requiring an API Key._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = # paste your API Key here as a string\n",
    "movie = \"The Matrix\"\n",
    "BASE_URL = \"http://www.omdbapi.com/\"\n",
    "URL = \"{}?apikey={}&t={}\".format(BASE_URL, API_KEY, movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delaying API requests in loops\n",
    "\n",
    "Let's query the OMBd API with a bunch of movies!\n",
    "\n",
    "It would be easy to create a loop and run all of the requests. However, our python code would execute everything within milliseconds of each other. This might cause the OMBd servers to assume we're a malicious attacker trying to cause a denial of service, so let's be respectful and include a short delay between our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\"The Matrix\", \"War Games\", \"Sneakers\",\"Tron\",\"The Net\"]\n",
    "\n",
    "API_KEY = # paste your API Key here as a string\n",
    "\n",
    "BASE_URL = \"http://www.omdbapi.com/\"\n",
    "\n",
    "results = [] # storing results\n",
    "\n",
    "for movie in movies:\n",
    "    # forming URL for each movie\n",
    "    URL = \"{}?apikey={}&t={}\".format(BASE_URL, API_KEY, movie)\n",
    "    \n",
    "    # making request and storing response\n",
    "    response = requests.get(URL)\n",
    "    \n",
    "    # converting response to Python Dictionary and adding to stored results\n",
    "    results.append(response.json())\n",
    "    \n",
    "    # adding delay\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert API data to DataFrame\n",
    "Lets take our results and add them to a dataframe.\n",
    "\n",
    "Thankfully, `pd.DataFrame()` is set up to handle dictionary-style datasets by assuming the keys serve as the column names and the values are the values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame(results)\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the first value in the \"Ratings\" column\n",
    "movie_df[\"Ratings\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convenience is great, but not perfect.  \n",
    "We see nested values, such as the \"Ratings\" column are difficult to parse.  \n",
    "However, we are set up to clean these data in typical Pandas fashion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data (pd.DataFrame) to a file\n",
    "Once you've obtained your data in memory, you'll want to store the information as a file on your hard drive. This will ensure you're not making redundant or excessive server requests.\n",
    "\n",
    "Simply take the DataFrame you've made and call `.to_csv(\"FILE_PATH\")` on it. Of course, there are other formats you can write to, but CSV is the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.to_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to saving your hard earned data as a file, you'll also want to keep a data dictionary on hand.\n",
    "\n",
    "A data dictionary serves as a description of the data features/columns. This is not only intended to better explain the structure and layout of your dataset, but serves as a check for anyone else looking at you work.\n",
    "\n",
    "Imagine having a column of data representing the surface area of a house as a simple integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Example Database:_\n",
    "\n",
    "Surface_Area|Age|Condition\n",
    "-|-|-\n",
    "100|19|G\n",
    "250|33|P\n",
    "350|24|S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data are certainly in a convenient format, but there are no units!\n",
    "\n",
    "The data dictionary is the place to describe your data, categories, etc.\n",
    "\n",
    "Also, when others review your work or try to replicate it, loading the data may result in the wrong datatype being assumed by the program loading the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Example Data Dictionary:_\n",
    "\n",
    "\n",
    "Column name | Data Type | Description\n",
    "-|-|-\n",
    "Surface_Area| Integer | Home's surface area (sq. feet)\n",
    "Age | Integer| Age of house (years)\n",
    "Condition | String | Home's current condition (P: Poor, G: Good, E: Excellent, S:Superb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Be sure to always include a data dictionary or reference to one!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the 'titanic.csv' and 'wine.csv' data files as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find, download and load a CSV file from a public dataset source\n",
    "Feel free to use [Kaggle](https://www.kaggle.com/) or other public data sites, such as \n",
    "Government sources (for example: https://www.data.gov/).\n",
    "\n",
    "The task is merely to download and load the data as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a website with a table-like set of data and scrape it\n",
    "Any website of your choosing will do, so long as you can pull relevant information from it.\n",
    "\n",
    "If you can find data that is not necessarily in a \"table-like\" formate, such as \"cards\" of information, that will do, too.\n",
    "Load at least 10 data points and create a Pandas DataFrame with the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find an API and request data\n",
    "APIs can be difficult to handle, especially since most will require signing up for a key or even a paid service.\n",
    "You would be surprised by the kinds of APIs that are available! \n",
    "\n",
    "Make enough requests to fill at least 20 rows of data and create a Pandas DataFrame with it.\n",
    "\n",
    "Here are some links to help spur some ideas (_NOTE: APIs are updated, changed, or outright removed at the discretion of the maintainers controlling it. Some of these link may be out of date!_):\n",
    "- [Google Static Maps API](https://developers.google.com/maps/documentation/maps-static/intro)\n",
    "- [Socrata Open Data API](https://dev.socrata.com/)\n",
    "- [NASA API (Check out DEMO_KEY Rate Limits)](https://api.nasa.gov/api.html)\n",
    "- [Spotify API](https://developer.spotify.com/documentation/web-api/)\n",
    "- [Wordnik API](https://developer.wordnik.com/)\n",
    "- [Giphy API](https://developers.giphy.com/docs/)\n",
    "- [Pokemon API](https://pokeapi.co/)\n",
    "- [Yoda (and other dialects) Translation API](http://funtranslations.com/api#yoda)\n",
    "- [Random Cat Images API](http://thecatapi.com/)\n",
    "- [National Nutrition Database API](https://ndb.nal.usda.gov/ndb/api/doc)\n",
    "- [ProgrammableWeb API Search](https://www.programmableweb.com/apis/directory)\n",
    "- [Public APIs](https://github.com/toddmotto/public-apis)\n",
    "- [Any API Website](https://any-api.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary:\n",
    "\n",
    "### Data Wrangling/Munging - ([source](https://en.wikipedia.org/wiki/Data_wrangling))\n",
    "- The process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics\n",
    "\n",
    "### Web Scraping - ([source](https://en.wikipedia.org/wiki/Data_scraping))\n",
    "- A technique to automatically extract data from a website\n",
    "\n",
    "### Application Programming Interface (API) - ([source](https://medium.com/@perrysetgo/what-exactly-is-an-api-69f36968a41f))\n",
    "- When people speak of \"an API\", they sometimes generalize and actually mean \"a publicly available web-based API that returns data, likely in JSON or XML\". The API is not the database or even the server, it is the code that governs the access point(s) for the server\n",
    "- Web based APIs return data in response to a request made by a client\n",
    "- An API brokers access to a different application to provide functionality or access to data, so data can be included in different applications\n",
    "\n",
    "### Denial of Service ([source](https://en.wikipedia.org/wiki/Denial-of-service_attack))\n",
    "- A cyber-attack in which the perpetrator seeks to make a machine or network resource unavailable to its intended users by temporarily or indefinitely disrupting services of a host connected to the Internet\n",
    "- This is typically accomplished by flooding the targeted machine or resource with superfluous requests in an attempt to overload systems and prevent some or all legitimate requests from being fulfilled\n",
    "\n",
    "### Data Dictionary ([source](https://en.wikipedia.org/wiki/Data_dictionary))\n",
    "- A centralized repository of information about data such as meaning, relationships to other data, origin, usage, and format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- [Pandas DataFrame Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [randomuser API](https://randomuser.me/)\n",
    "- [pokeapi API](https://pokeapi.co/)\n",
    "- [omdbapi API](http://www.omdbapi.com/)\n",
    "- [Kaggle](https://www.kaggle.com/)\n",
    "- [Google Static Maps API](https://developers.google.com/maps/documentation/maps-static/intro)\n",
    "- [Socrata Open Data API](https://dev.socrata.com/)\n",
    "- [NASA API (Check out DEMO_KEY Rate Limits)](https://api.nasa.gov/api.html)\n",
    "- [Spotify API](https://developer.spotify.com/documentation/web-api/)\n",
    "- [Wordnik API](https://developer.wordnik.com/)\n",
    "- [Giphy API](https://developers.giphy.com/docs/)\n",
    "- [Pokemon API](https://pokeapi.co/)\n",
    "- [Yoda (and other dialects) Translation API](http://funtranslations.com/api#yoda)\n",
    "- [Random Cat Images API](http://thecatapi.com/)\n",
    "- [National Nutrition Database API](https://ndb.nal.usda.gov/ndb/api/doc)\n",
    "- [ProgrammableWeb API Search](https://www.programmableweb.com/apis/directory)\n",
    "- [Public APIs](https://github.com/toddmotto/public-apis)\n",
    "- [Any API Website](https://any-api.com/)\n",
    "- [How HTML works (video)](https://www.youtube.com/watch?v=bWPMSSsVdPk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have Feedback?\n",
    "[Submit feedback here](https://docs.google.com/forms/d/e/1FAIpQLScvsDT2Q2VH26FvvfQhjNmP4RwXqh9GWiKSIcTFAHdfCKZdlg/viewform?usp=sf_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
